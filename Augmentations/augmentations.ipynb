{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the imbalanced nature of our dataset, we have to carefully split the images into a representative training, validation and test set. We decide to have at least one of each bodypart classes in the validation and test sets. Moreover, we artificially augment our imbalanced 105 training images into 7000 by applying different transformations in a way that we generate more images from the unrepresented bodyparts. The filters we use are gaussian noise, spatial transformations and elastic transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1832/4196087338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom_crop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle_together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbalanced_test_val_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Visiomex\\AppData\\Local\\GitHubDesktop\\app-2.9.0\\XNet\\Augmentations\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\rasterio\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgdal_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrivers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdriver_from_extension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_blacklisted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m from rasterio.dtypes import (\n",
      "\u001b[1;32mrasterio\\_base.pyx\u001b[0m in \u001b[0;36minit rasterio._base\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mrasterio\\_shim.pyx\u001b[0m in \u001b[0;36minit rasterio._shim\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "from __future__ import division\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import os, sys\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from IPython.display import clear_output\r\n",
    "import imgaug as ia\r\n",
    "from imgaug import augmenters as iaa\r\n",
    "from imgaug import parameters as iap\r\n",
    "import cv2\r\n",
    "import glob\r\n",
    "import sys\r\n",
    "sys.path.append('../')\r\n",
    "from Training import create_h5\r\n",
    "from random import shuffle\r\n",
    "import h5py\r\n",
    "import argparse\r\n",
    "import rgb2label as gen_label\r\n",
    "import scipy.misc\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "import random\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from utils import random_crop\r\n",
    "from utils import shuffle_together\r\n",
    "from utils import balanced_test_val_split\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\r\n",
    "\r\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS\n",
    "Main path where images and labels are stored. In data to add, we can select only human data, ct or phantom images. The parameter EXAMPLES_PER_CATEGORY controls the number of images per bodypart after augmenting the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"Data\"\n",
    "data_to_add = ['Humans','CT','Phantom'] \n",
    "EXAMPLES_PER_CATEGORY = 6\n",
    "\n",
    "image_size = 200\n",
    "train_size = 0.7\n",
    "n_classes = 3\n",
    "\n",
    "\n",
    "# output hdf5 file\n",
    "hdf5_name = '_'.join(data_to_add) \n",
    "\n",
    "if(EXAMPLES_PER_CATEGORY == 0):\n",
    "    hdf5_name = hdf5_name + '_s' + str(image_size) + '.hdf5'\n",
    "\n",
    "else:\n",
    "    hdf5_name =  hdf5_name +'_s'+str(image_size)+'_a'+ str(EXAMPLES_PER_CATEGORY)+ '.hdf5'\n",
    "\n",
    "hdf5_path = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN TEST VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels and data match in Humans folder ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1124/2730477550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimages_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilenames_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames_val\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbalanced_test_val_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_to_add\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Save hdf5 file without augmentations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Visiomex\\AppData\\Local\\GitHubDesktop\\app-2.9.0\\XNet\\Augmentations\\utils.py\u001b[0m in \u001b[0;36mbalanced_test_val_split\u001b[1;34m(main_path, data_to_add, image_size, train_size, n_classes)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[1;31m#print('Checking if number of labeled files matches number of data image files....')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m# Check that number of labels corresponds to number of images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get balanced body parts split into train test and validation sets\n",
    "images_train, labels_train, body_train, filenames_train, images_test, labels_test, body_test, \\\n",
    "filenames_test, images_val, labels_val, body_val, filenames_val = \\\n",
    "balanced_test_val_split(main_path, data_to_add, image_size, train_size, n_classes)\n",
    "\n",
    "# Save hdf5 file without augmentations\n",
    "create_h5.write_h5(\"final_noaug.hdf5\", images_train, labels_train/255, body_train,filenames_train, \\\n",
    "                   images_test, labels_test/255,body_test,filenames_test,\\\n",
    "images_val, labels_val/255,body_val ,filenames_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of augmentations per image in order to have a balanced training set\n",
    "\n",
    "unique, counts = np.unique(body_train, return_counts=True)\n",
    "unique_per_category = dict(zip(unique, counts))\n",
    "augmentations_per_category = dict(unique_per_category)\n",
    "for key in unique_per_category:\n",
    "    augmentations_per_category[key] = int(EXAMPLES_PER_CATEGORY/unique_per_category[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation templates\n",
    "translate_max = 0.01\n",
    "rotate_max = 15\n",
    "shear_max = 2\n",
    "crop_min = 0.1\n",
    "crop_max = 0.4\n",
    "\n",
    "affine_trasform = iaa.Affine( translate_percent={\"x\": (-translate_max, translate_max),\n",
    "                                                 \"y\": (-translate_max, translate_max)}, # translate by +-\n",
    "                              rotate=(-rotate_max, rotate_max), # rotate by -rotate_max to +rotate_max degrees\n",
    "                              shear=(-shear_max, shear_max), # shear by -shear_max to +shear_max degrees\n",
    "                              order=[1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                              cval=125, # if mode is constant, use a cval between 0 and 255\n",
    "                              mode=\"reflect\",\n",
    "                              #mode = \"\",\n",
    "                              name=\"Affine\",\n",
    "                             )\n",
    "\n",
    "\n",
    "spatial_aug = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5), affine_trasform])\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "other_aug = iaa.SomeOf((1, None),\n",
    "        [\n",
    "            iaa.OneOf([\n",
    "                iaa.GaussianBlur((0, 0.4)), # blur images with a sigma between 0 and 1.0\n",
    "            ]),\n",
    "\n",
    "        ])\n",
    "\n",
    "elastic_aug = iaa.SomeOf((1, None),\n",
    "        [\n",
    "            iaa.OneOf([\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(50, 60), sigma=16)), \n",
    "                # move pixels locally around (with random strengths)\n",
    "            ]),\n",
    "\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aaugmented set and save train data in it\n",
    "augmentators = [spatial_aug,other_aug, elastic_aug]\n",
    "total_images=sum(augmentations_per_category[k]*unique_per_category[k] + unique_per_category[k]\\\n",
    "                 for k in augmentations_per_category)\n",
    "images_aug = np.zeros((total_images,images_train.shape[1],images_train.shape[2],images_train.shape[3]))\n",
    "labels_aug = np.zeros((total_images,labels_train.shape[1],labels_train.shape[2],labels_train.shape[3]))\n",
    "bodypart = np.empty((total_images),dtype = 'S10')\n",
    "filenames_aug = np.empty((total_images),dtype = 'S60')\n",
    "\n",
    "images_aug[:images_train.shape[0],...] = images_train\n",
    "labels_aug[:images_train.shape[0],...] = labels_train/255\n",
    "bodypart[:images_train.shape[0],...] = body_train\n",
    "filenames_aug[:images_train.shape[0],...] = filenames_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Category b'tibia') processing image 98/105, augmented image 6/6\n"
     ]
    }
   ],
   "source": [
    "# Loop  over the different bodyparts\n",
    "counter = images_train.shape[0]\n",
    "counter_block = 0\n",
    "for i, (k, v) in enumerate(augmentations_per_category.items()):\n",
    "    # Indices of images with a given bodypart\n",
    "    indices = np.array(np.where(body_train == k )[0])\n",
    "    counter_block += len(indices)\n",
    "    # Number of augmentation per image\n",
    "    N = int(v)\n",
    "\n",
    "    for j in indices:\n",
    "        for l in range(N):\n",
    "            clear_output(wait=True)\n",
    "            # Freeze randomization to apply same to labels\n",
    "            spatial_det = augmentators[0].to_deterministic()\n",
    "            # to deterministic is needed to apply exactly the same spatial transformation to the data and the labels\n",
    "            other_augs = augmentators[1]\n",
    "            # When only adding noise there's no need to perform the transformation on the label\n",
    "            elastic_det = augmentators[2].to_deterministic()\n",
    "            \n",
    "            images_aug[counter,...] = spatial_det.augment_image(images_train[j])\n",
    "            labels_aug[counter,...] = spatial_det.augment_image(labels_train[j])\n",
    "\n",
    "\n",
    "            images_aug[counter,...] = elastic_det.augment_image(images_aug[counter,...])\n",
    "            labels_aug[counter,...]  = elastic_det.augment_image(labels_aug[counter,...] )\n",
    "\n",
    "            images_aug[counter,...], labels_aug[counter,...] = random_crop(images_aug[counter,...] ,\\\n",
    "                                                                labels_aug[counter,...] ,crop_min,crop_max)\n",
    "            images_aug[counter,...]  = other_aug.augment_image(images_aug[counter,...] )    \n",
    "\n",
    "\n",
    "            labels_aug[counter,...]  = to_categorical(np.argmax(labels_aug[counter,...] ,axis=-1), num_classes = 3)\n",
    "            # only needed if performing elastic transformations\n",
    "            bodypart[counter] = k \n",
    "            \n",
    "            filenames_aug[counter] = b'aug_' + filenames_train[j]\n",
    "            print('(Category %s) processing image %i/%i, augmented image %i/%i'%(k,counter_block ,\n",
    "                                                                                     body_train.shape[0],\n",
    "                                                                                     l+1, N))\n",
    "            counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1832/1044367293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Show some of the augmented images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moriginal_hand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_aug\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34mb'hand_friday_21_october'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maug_hands\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_aug\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34mb'aug_hand'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_hand\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maug_hands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'col'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames_aug' is not defined"
     ]
    }
   ],
   "source": [
    "# Show some of the augmented images\n",
    "original_hand = [i for i, s in enumerate(filenames_aug) if s==b'hand_friday_21_october']\n",
    "aug_hands =  [i for i, s in enumerate(filenames_aug) if b'aug_hand' in s]\n",
    "hands = original_hand + aug_hands\n",
    "fig, ax = plt.subplots(1,len(hands), sharey='row', sharex='col',figsize=(30,30))\n",
    "\n",
    "for j in range(len(hands)):\n",
    "    ax[j].imshow(images_aug[hands[j],...,0],cmap='gray')\n",
    "    ax[j].imshow(labels_aug[hands[j]],alpha=0.1)\n",
    "    ax[j].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished playing with cadavers ! \n"
     ]
    }
   ],
   "source": [
    "# Shuffle the images again\n",
    "images_aug, labels_aug, bodypart, filenames_aug = shuffle_together(images_aug, labels_aug, bodypart, filenames_aug)\n",
    "\n",
    "images_test, labels_test, body_test, filenames_test = shuffle_together(images_test, labels_test, body_test, \\\n",
    "                                                                       filenames_test)\n",
    "\n",
    "images_val, labels_val, body_val, filenames_val = shuffle_together(images_val, labels_val, body_val, filenames_val)\n",
    "\n",
    "print('Finished playing with cadavers ! ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the hdf5 at Humans_CT_Phantom_s200_a6.hdf5 ...\n"
     ]
    }
   ],
   "source": [
    "create_h5.write_h5(hdf5_path + hdf5_name, images_aug, labels_aug, bodypart,filenames_aug, images_test, \\\n",
    "            labels_test/255,body_test,filenames_test,images_val, labels_val/255,body_val ,filenames_val)\n",
    "\n",
    "\n",
    "print('Saving the hdf5 at %s ...'%hdf5_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1840c60ede238b2a9995e575fde62eea1d8741c08f0d45f2168a8c4c453106be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}